{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1c5486",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch import optim\n",
    "from utils import *\n",
    "from modules import UNet\n",
    "import logging\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "logging.basicConfig(format=\"%(asctime)s - %(levelname)s: %(message)s\", level=logging.INFO, datefmt=\"%I:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f87804",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"zy\" \"test\" \"again\" \"test\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36fa6bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_linear_schedule(T, low, high):\n",
    "    return torch.linspace(low, high, T)\n",
    "\n",
    "def generate_cosine_schedule(T, s=0.008):\n",
    "    def f(t, T):\n",
    "        return (np.cos((t / T + s) / (1 + s) * np.pi / 2)) ** 2\n",
    "    \n",
    "    alphas = []\n",
    "    f0 = f(0, T)\n",
    "\n",
    "    for t in range(T + 1):\n",
    "        alphas.append(f(t, T) / f0)\n",
    "    \n",
    "    betas = []\n",
    "\n",
    "    for t in range(1, T + 1):\n",
    "        betas.append(min(1 - alphas[t] / alphas[t - 1], 0.999))\n",
    "    \n",
    "    return torch.tensor(betas)\n",
    "#betas = generate_linear_schedule(20)\n",
    "betas = generate_linear_schedule(20, 1e-4, 0.002)\n",
    "alpha = 1 -  betas\n",
    "alpha_hat = torch.cumprod(alpha,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18f245ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9999, 0.9997, 0.9994, 0.9990, 0.9985, 0.9979, 0.9972, 0.9964, 0.9955,\n",
       "        0.9945, 0.9934, 0.9922, 0.9909, 0.9895, 0.9881, 0.9865, 0.9848, 0.9830,\n",
       "        0.9812, 0.9792])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2738c78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "t=torch.tensor([3, 3, 3, 3, 3])\n",
    "t=torch.tensor([2, 2, 2, 2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44a5106e",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_hat[t]\n",
    "sqrt_alpha_hat = torch.sqrt(alpha_hat[t])\n",
    "sqrt_one_minus_alpha_hat = torch.sqrt(1 - alpha_hat[t])\n",
    "Ɛ = torch.randn_like(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fef3318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9997, 0.9997, 0.9997, 0.9997, 0.9997])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqrt_alpha_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86e347ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.4683,  1.1691, -1.7642,  0.5617],\n",
       "          [ 0.3483, -0.2771, -1.0007, -2.1744],\n",
       "          [ 0.5816, -0.7072, -1.7514, -0.4293],\n",
       "          [ 2.0705,  0.6799, -0.9155,  0.0820]],\n",
       "\n",
       "         [[-0.9093, -0.5691,  1.6219, -1.8850],\n",
       "          [ 0.3668, -0.9200,  1.4821, -0.6295],\n",
       "          [-1.5128,  0.2808, -0.6758, -0.0405],\n",
       "          [-0.2306, -0.7444,  0.1601, -2.8858]],\n",
       "\n",
       "         [[ 0.9065, -0.7184, -0.1060, -0.8009],\n",
       "          [ 1.1315,  0.4494, -0.9772,  1.2910],\n",
       "          [-0.4895, -0.7633,  0.2498,  0.4242],\n",
       "          [ 0.2720,  1.2698, -0.2295,  0.2178]]],\n",
       "\n",
       "\n",
       "        [[[ 0.5923,  0.5806,  1.0161,  0.5673],\n",
       "          [-2.3601, -0.4190,  0.4690, -0.1333],\n",
       "          [-0.0908,  0.2838, -0.5827, -0.9176],\n",
       "          [-0.3681, -0.9478,  1.6393,  1.0664]],\n",
       "\n",
       "         [[ 0.4388, -1.1634, -0.1718,  0.5890],\n",
       "          [ 0.6816, -0.2970, -1.1076,  0.4461],\n",
       "          [ 0.6595,  0.3420,  1.4287, -1.7068],\n",
       "          [ 1.1961, -0.8003, -1.2595, -1.5792]],\n",
       "\n",
       "         [[ 1.1090, -0.6468, -1.4336,  1.2399],\n",
       "          [-0.3763,  0.1762, -1.3545, -0.6393],\n",
       "          [ 1.5551, -0.3651,  1.0714,  1.5859],\n",
       "          [ 1.3492, -0.3844, -0.1875, -0.2084]]],\n",
       "\n",
       "\n",
       "        [[[ 2.6212, -0.1528,  1.4553, -0.4075],\n",
       "          [ 0.5075,  0.0534, -0.6166,  1.4921],\n",
       "          [-1.0364,  0.0937, -0.4824, -1.4802],\n",
       "          [ 0.2951,  0.3834, -0.9705,  0.7056]],\n",
       "\n",
       "         [[ 0.6470,  1.1720, -1.5235, -0.5038],\n",
       "          [-1.1437, -0.2121, -0.4623,  0.3483],\n",
       "          [-0.6539, -0.6511, -0.8937,  0.3237],\n",
       "          [ 2.1677,  0.9192,  0.1469, -0.7422]],\n",
       "\n",
       "         [[ 0.2250, -0.3289,  1.5221,  1.4139],\n",
       "          [ 0.8835, -0.5910,  0.8824,  1.0221],\n",
       "          [-0.7995,  0.8626, -0.4299,  1.3447],\n",
       "          [ 1.5445, -0.6899, -1.8709, -0.0389]]],\n",
       "\n",
       "\n",
       "        [[[-0.2548,  0.8428,  1.2354, -0.3189],\n",
       "          [ 1.3696, -1.1335,  1.3094,  0.2300],\n",
       "          [-0.5331, -0.5436, -1.6454, -1.5430],\n",
       "          [ 1.6667, -0.5925, -0.3323, -0.9463]],\n",
       "\n",
       "         [[ 0.2941, -0.6137, -1.5427, -0.2986],\n",
       "          [ 1.1419, -1.5453,  0.3688, -0.6358],\n",
       "          [ 0.6369, -1.0309,  1.9481,  1.0425],\n",
       "          [-0.9795,  0.8034,  0.3899,  0.6939]],\n",
       "\n",
       "         [[-1.5927,  2.0830, -0.5322, -0.1384],\n",
       "          [ 0.2012,  0.7804,  0.4473, -1.0755],\n",
       "          [ 0.2322, -2.0395, -0.2544,  2.0589],\n",
       "          [ 0.7961,  1.3223, -1.3609, -0.2768]]],\n",
       "\n",
       "\n",
       "        [[[ 1.2981,  0.1113, -0.3801,  0.4326],\n",
       "          [ 1.1724,  0.8052,  0.7997, -0.1771],\n",
       "          [-1.3853,  0.1606,  0.1266, -2.0546],\n",
       "          [ 1.8344, -1.0355,  2.3637, -0.4520]],\n",
       "\n",
       "         [[-0.6198,  0.6573, -0.1943,  0.2334],\n",
       "          [-0.7770,  0.6276, -0.2740,  1.3274],\n",
       "          [ 0.9950,  0.0257,  0.2440, -1.0677],\n",
       "          [ 1.4476, -0.1635,  0.7289,  2.6188]],\n",
       "\n",
       "         [[ 1.0907, -0.1125, -2.8476, -0.1516],\n",
       "          [-2.7172, -0.3978, -0.0677, -0.7991],\n",
       "          [-0.1942,  0.4890,  0.4478,  0.0924],\n",
       "          [-0.4055, -1.5693, -1.0721, -2.4545]]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn((5, 3, 4,4))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "785d02a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sqrt_alpha_hat = torch.sqrt(alpha_hat[t])[:, None, None, None]\n",
    "#sqrt_alpha_hat = torch.sqrt(alpha_hat[t]).reshape(5,1,1,1)\n",
    "sqrt_one_minus_alpha_hat = torch.sqrt(1 - alpha_hat[t])[:, None, None, None]\n",
    "Ɛ = torch.randn_like(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34eb5558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 1, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqrt_alpha_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2cffe86c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.3286, -0.2353,  0.0991, -1.3773],\n",
       "          [-0.7290, -0.1598, -0.4245, -0.4987],\n",
       "          [-0.2052, -0.4233, -0.7123, -0.0087],\n",
       "          [-0.3423, -0.3240,  0.9511,  0.7970]],\n",
       "\n",
       "         [[-0.4586,  0.3034, -0.2492,  0.0521],\n",
       "          [-0.2235, -0.5247,  0.3555, -0.9259],\n",
       "          [ 0.1602,  0.1333, -0.0447, -0.4147],\n",
       "          [ 0.2762, -0.0651, -0.0933,  0.3236]],\n",
       "\n",
       "         [[ 0.6375,  0.6065, -0.0302, -0.1874],\n",
       "          [-0.3175,  0.3098,  0.7919,  0.8397],\n",
       "          [-0.7901,  0.1536, -0.1100,  0.2060],\n",
       "          [-0.9524, -0.2805,  0.7237, -0.1172]]],\n",
       "\n",
       "\n",
       "        [[[-0.0116,  0.5159, -0.4975,  0.8877],\n",
       "          [ 0.0821, -0.0336,  0.4018,  0.0297],\n",
       "          [-0.9150,  0.3500, -0.5068, -0.4641],\n",
       "          [-0.3773,  0.4975,  0.2511,  0.0233]],\n",
       "\n",
       "         [[ 0.6040,  0.2400, -0.2427, -0.0272],\n",
       "          [ 0.2798, -0.3201,  0.4901,  0.3335],\n",
       "          [-0.0325, -0.1514, -0.2679,  0.4987],\n",
       "          [ 0.5815,  0.2390,  0.0127, -0.4465]],\n",
       "\n",
       "         [[-0.4399, -0.4309,  0.4833, -0.7376],\n",
       "          [-0.5875, -0.8940,  0.8112,  0.0277],\n",
       "          [-0.2261,  0.3489, -0.0650,  0.4580],\n",
       "          [-0.5457, -0.2801,  0.2214,  0.2153]]],\n",
       "\n",
       "\n",
       "        [[[-0.5937, -0.4306,  0.7367, -0.2753],\n",
       "          [ 0.5067, -0.0644, -0.2803, -0.1941],\n",
       "          [-0.3666, -0.1321,  0.1184, -0.2768],\n",
       "          [ 0.3785,  0.0351,  0.4586,  0.4739]],\n",
       "\n",
       "         [[-0.6294,  1.0810,  0.1772,  0.0640],\n",
       "          [ 0.0431,  0.6989,  0.0897,  0.3652],\n",
       "          [-0.7521, -0.7744,  0.2450, -0.1743],\n",
       "          [-0.9759,  0.4852, -0.1698, -0.6515]],\n",
       "\n",
       "         [[ 0.2721, -0.2088, -0.3042,  0.0193],\n",
       "          [ 1.3853,  0.2648, -0.6220, -0.1737],\n",
       "          [ 0.3644, -0.2837, -0.5229,  0.1484],\n",
       "          [-0.3859,  0.1380,  0.3951,  0.3998]]],\n",
       "\n",
       "\n",
       "        [[[-0.2405,  0.7041, -0.2042, -0.1803],\n",
       "          [ 0.1545,  0.5546,  0.4150,  0.3137],\n",
       "          [-0.1922,  0.4258, -0.1865, -0.2630],\n",
       "          [-0.4524,  0.0449, -0.4792,  0.1610]],\n",
       "\n",
       "         [[-0.3123,  0.3666,  0.7489, -0.0148],\n",
       "          [-0.4298,  0.0823, -0.4743, -0.3048],\n",
       "          [-0.6025, -0.8304,  0.3802,  0.3746],\n",
       "          [-0.5377, -0.2421,  0.0333, -0.5685]],\n",
       "\n",
       "         [[-0.7480,  0.0977,  0.4788,  0.5589],\n",
       "          [-0.3474, -0.7419, -0.1521,  0.5986],\n",
       "          [-0.5332, -0.5489,  0.1349, -0.0969],\n",
       "          [ 0.2411, -0.1399, -0.0119,  0.7162]]],\n",
       "\n",
       "\n",
       "        [[[ 0.2203, -0.7643,  0.7804, -0.1023],\n",
       "          [-0.0229,  0.2338,  0.2824,  0.3828],\n",
       "          [ 0.2671, -0.5689,  0.3066,  0.3089],\n",
       "          [-0.1719,  0.3755,  0.4310, -0.8513]],\n",
       "\n",
       "         [[-0.1854,  0.7710,  0.1671,  0.2186],\n",
       "          [-0.3388, -0.4502, -0.2452,  0.4154],\n",
       "          [ 0.6316, -0.1203,  0.7862,  0.1732],\n",
       "          [-0.3811, -1.1182, -0.1070, -0.6083]],\n",
       "\n",
       "         [[-0.2225,  0.0904,  0.1529,  0.5188],\n",
       "          [ 0.0130,  0.0522, -0.5245, -0.1105],\n",
       "          [-0.0056,  0.3699,  0.4936, -0.1318],\n",
       "          [ 0.8926, -0.1302, -0.8091,  0.1704]]]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqrt_alpha_hat * x + sqrt_one_minus_alpha_hat * Ɛ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "87d375dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9,  1, 17,  7, 12])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sample_timesteps(n):\n",
    "    return torch.randint(low=1, high=20, size=(n,))\n",
    "sample_timesteps(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d603cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Diffusion:\n",
    "    def __init__(self, noise_steps=1000, beta_start=1e-4, beta_end=0.02, img_size=256, device=\"cuda\"):\n",
    "        self.noise_steps = noise_steps\n",
    "        self.beta_start = beta_start\n",
    "        self.beta_end = beta_end\n",
    "        self.img_size = img_size\n",
    "        self.device = device\n",
    "        self.beta = self.prepare_noise_schedule().to(device)\n",
    "        self.alpha = 1. - self.beta\n",
    "        self.alpha_hat = torch.cumprod(self.alpha, dim=0)\n",
    "\n",
    "    def prepare_noise_schedule(self, use_cosine=False, s=0.008):  \n",
    "        if use_cosine == True:\n",
    "            def f(t, self.noise_steps):\n",
    "                return (np.cos((t / self.noise_steps + s) / (1 + s) * np.pi / 2)) ** 2\n",
    "            alphas = []\n",
    "            f0 = f(0, self.noise_steps)\n",
    "            for t in range(self.noise_steps + 1):\n",
    "                alphas.append(f(t, self.noise_steps) / f0)\n",
    "            betas = []\n",
    "            for t in range(1, self.noise_steps + 1):\n",
    "                betas.append(min(1 - alphas[t] / alphas[t - 1], 0.999))\n",
    "            return torch.tensor(betas)\n",
    "        else:\n",
    "            return torch.linspace(self.beta_start, self.beta_end, self.noise_steps)\n",
    "\n",
    "    def noise_images(self, x, t):\n",
    "        sqrt_alpha_hat = torch.sqrt(self.alpha_hat[t])[:, None, None, None]\n",
    "        sqrt_one_minus_alpha_hat = torch.sqrt(1 - self.alpha_hat[t])[:, None, None, None]\n",
    "        Ɛ = torch.randn_like(x)\n",
    "        return sqrt_alpha_hat * x + sqrt_one_minus_alpha_hat * Ɛ, Ɛ\n",
    "\n",
    "    def sample_timesteps(self, n):\n",
    "        return torch.randint(low=1, high=self.noise_steps, size=(n,))\n",
    "\n",
    "    def sample(self, model, n):\n",
    "        logging.info(f\"Sampling {n} new images....\")\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            x = torch.randn((n, 3, self.img_size, self.img_size)).to(self.device)\n",
    "            for i in tqdm(reversed(range(1, self.noise_steps)), position=0):\n",
    "                t = (torch.ones(n) * i).long().to(self.device)\n",
    "                predicted_noise = model(x, t)\n",
    "                alpha = self.alpha[t][:, None, None, None]\n",
    "                alpha_hat = self.alpha_hat[t][:, None, None, None]\n",
    "                beta = self.beta[t][:, None, None, None]\n",
    "                if i > 1:\n",
    "                    noise = torch.randn_like(x)\n",
    "                else:\n",
    "                    noise = torch.zeros_like(x)\n",
    "                x = 1 / torch.sqrt(alpha) * (x - (beta / (torch.sqrt(1 - alpha_hat))) * predicted_noise) + torch.sqrt(beta) * noise\n",
    "        model.train()\n",
    "        x = (x.clamp(-1, 1) + 1) / 2\n",
    "        x = (x * 255).type(torch.uint8)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f32481",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args):\n",
    "    setup_logging(args.run_name)\n",
    "    device = args.device\n",
    "    dataloader = get_data(args)\n",
    "    model = UNet().to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=args.lr)\n",
    "    mse = nn.MSELoss()\n",
    "    diffusion = Diffusion(img_size=args.image_size, device=device)\n",
    "    logger = SummaryWriter(os.path.join(\"runs\", args.run_name))\n",
    "    l = len(dataloader)\n",
    "\n",
    "    for epoch in range(args.epochs):\n",
    "        logging.info(f\"Starting epoch {epoch}:\")\n",
    "        pbar = tqdm(dataloader)\n",
    "        for i, (images, _) in enumerate(pbar):\n",
    "            images = images.to(device)\n",
    "            t = diffusion.sample_timesteps(images.shape[0]).to(device)\n",
    "            x_t, noise = diffusion.noise_images(images, t)\n",
    "            predicted_noise = model(x_t, t)\n",
    "            loss = mse(noise, predicted_noise)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            pbar.set_postfix(MSE=loss.item())\n",
    "            logger.add_scalar(\"MSE\", loss.item(), global_step=epoch * l + i)\n",
    "\n",
    "        sampled_images = diffusion.sample(model, n=images.shape[0])\n",
    "        save_images(sampled_images, os.path.join(\"results\", args.run_name, f\"{epoch}.jpg\"))\n",
    "        torch.save(model.state_dict(), os.path.join(\"models\", args.run_name, f\"ckpt.pt\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f677236c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def launch():\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser()\n",
    "    args = parser.parse_args()\n",
    "    args.run_name = \"DDPM_Uncondtional\"\n",
    "    args.epochs = 500\n",
    "    args.batch_size = 12\n",
    "    args.image_size = 64\n",
    "    args.dataset_path = r\"C:\\Users\\----------------------------\"\n",
    "    args.device = \"cuda\"\n",
    "    args.lr = 3e-4\n",
    "    train(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a016d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6285bdac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0cc433",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f725408b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733a0850",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c6ea2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3040cc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # device = \"cuda\"\n",
    "    # model = UNet().to(device)\n",
    "    # ckpt = torch.load(\"./working/orig/ckpt.pt\")\n",
    "    # model.load_state_dict(ckpt)\n",
    "    # diffusion = Diffusion(img_size=64, device=device)\n",
    "    # x = diffusion.sample(model, 8)\n",
    "    # print(x.shape)\n",
    "    # plt.figure(figsize=(32, 32))\n",
    "    # plt.imshow(torch.cat([\n",
    "    #     torch.cat([i for i in x.cpu()], dim=-1),\n",
    "    # ], dim=-2).permute(1, 2, 0).cpu())\n",
    "    # plt.show()"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
